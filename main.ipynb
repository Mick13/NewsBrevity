{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Part 1\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlalchemy import create_engine, text\n",
    "import uuid\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "def retrieve_text_from_url(url):\n",
    "  \"\"\"Remove html tags from a string\"\"\"\n",
    "  try:\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "  except:\n",
    "    return\"\"\n",
    "\n",
    "\n",
    "def get_news(keyword):\n",
    "  newsapi_key = 'ffba3148c6d1447ca0b54113757555e0'\n",
    "  endpoint = 'https://newsapi.org/v2/everything'\n",
    "  parameters = {\n",
    "      'q': keyword,\n",
    "      'apiKey' : newsapi_key,\n",
    "      'pagesize' : 100\n",
    "  }\n",
    "  data = requests.get(endpoint, params = parameters).json()\n",
    "  #Get the full text for the articles\n",
    "  for article in data['articles']:\n",
    "    article['full_text'] = retrieve_text_from_url(article['url'])\n",
    "  return data['articles']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Instructions\n",
    "\n",
    "In this assignment, we will explore how to combine two powerful APIs - NewsAPI and ChatGPT - to create a pipeline that retrieves news articles, analyzes their sentiment and entities, and stores the results in a database. The NewsAPI provides us with access to a wealth of news articles, while ChatGPT allows us to extract valuable insights from these articles. By integrating these APIs together and storing the results in a database, we can create a powerful tool for analyzing and understanding the news. In the following sections, we will walk through the steps required to build this pipeline and explore some of the challenges and opportunities along the way.\n",
    "\n",
    "Part 1:\n",
    "\n",
    "Use the NewsAPI to get URLs for news articles. Go to https://newsapi.org, create an account, and get a key. Use the https://newsapi.org/v2/everything endpoint, which inputs a keyword, queries the NewsAPI, and returns a list of URLs with the news stories containing the keyword. Follow the documentation at https://newsapi.org/#documentation and figure out how to get back the news. Similarly, create an account with OpenAI, and sign up to use their API. You will need to enter your credit card info, as the API charges on a per-use basis. (The charges are not high as the usage in this project is going to be rather minimal.)\n",
    "\n",
    "Part 2:\n",
    "\n",
    "Write code that stores the retrieved news articles in a database. You can use the db.ipeirotis.org MySQL server and create your table under the public database.\n",
    "\n",
    "Please prefix with your netID all the tables you create in the public database. So, if you want to create a table called news and your netID is ab123, call the table ab123_news.\n",
    "\n",
    "You will need to figure out which fields you want to save in the database, and their data types, create the appropriate table, and then insert in the database the news entries that you retrieved in Part 1.\n",
    "\n",
    "Part 3:\n",
    "\n",
    "Retrieve the news articles you stored in the database in Part 2, and use the ChatGPT to extract (a) the sentiment of each of the news articles, (b) the entities discussed in the text, and (c) anything else that you want to extract.\n",
    "\n",
    "Part 4:\n",
    "\n",
    "Store in the database the sentiment, entities, and the additional element that you extracted from each news article. The sentiment table should contain just two fields, url and sentiment_score. The entities table should contain url and entity. You will probably need a table with a similar structure for whatever you want to extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: feedparser in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (6.0.10)\n",
      "Requirement already satisfied: sgmllib3k in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from feedparser) (1.0.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mysql-connector-python in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (8.1.0)\n",
      "Requirement already satisfied: protobuf<=4.21.12,>=4.21.1 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from mysql-connector-python) (4.21.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install feedparser\n",
    "!pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "def test_connection():\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        port=8889,   \n",
    "        user='root',         \n",
    "        password='root',     \n",
    "        database='news_articles_db'\n",
    "    )\n",
    "    if connection.is_connected():\n",
    "        print(\"Connected to the database!\")\n",
    "        connection.close()\n",
    "    else:\n",
    "        print(\"Failed to connect.\")\n",
    "\n",
    "test_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_article_in_db(article, connection):\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    insert_query = \"\"\"INSERT INTO news_articles (title, summary, link, published)\n",
    "                      VALUES (%s, %s, %s, %s)\"\"\"\n",
    "    \n",
    "    title = article['title']\n",
    "    summary = article['summary']\n",
    "    link = article['link']\n",
    "    published = article['published']\n",
    "\n",
    "    cursor.execute(insert_query, (title, summary, link, published))\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "\n",
    "def retrieve_articles_from_db(connection):\n",
    "    cursor = connection.cursor(dictionary=True)\n",
    "    \n",
    "    select_query = \"SELECT * FROM articles\"\n",
    "    \n",
    "    cursor.execute(select_query)\n",
    "    articles = cursor.fetchall()\n",
    "    \n",
    "    cursor.close()\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arm: Chip designer to the world in $54bn market return\n",
      "Arm shares were priced at the top of the range that had been indicated to prospective investors.\n",
      "Link: https://www.bbc.co.uk/news/business-66805116?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-14\n",
      "-------------------------------\n",
      "'Overwhelming consensus' on AI regulation - Musk\n",
      "Tech heavyweights gathered in Washington DC to discuss the regulation of artificial intelligence.\n",
      "Link: https://www.bbc.co.uk/news/technology-66804996?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-13\n",
      "-------------------------------\n",
      "AI and sound - helping firms build their own 'sonic identity'\n",
      "Artificial intelligence is assisting companies in developing their own signature sounds.\n",
      "Link: https://www.bbc.co.uk/news/business-66330890?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-13\n",
      "-------------------------------\n",
      "France halts iPhone 12 sales over radiation levels\n",
      "Apple has been told it must recall every iPhone 12 sold in the country if it cannot fix the problem.\n",
      "Link: https://www.bbc.co.uk/news/technology-66795168?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-13\n",
      "-------------------------------\n",
      "iPhone 15: Apple forced to ditch lightning charger\n",
      "Apple confirms new iPhone 15 will have a common USB-C charging port after the EU forced the change.\n",
      "Link: https://www.bbc.co.uk/news/technology-66778528?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-13\n",
      "-------------------------------\n",
      "AI quiz: Can you tell which image is real?\n",
      "Test your skills at spotting AI-generated images with Bitesize's monthly AI quiz.\n",
      "Link: https://www.bbc.co.uk/bitesize/articles/zktxfdm?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-13\n",
      "-------------------------------\n",
      "Cryptoqueen: Accomplice jailed for 20 years for OneCoin financial scam\n",
      "Sebastian Karl Greenwood was sentenced by a US judge for the massive scam that stole billions from investors.\n",
      "Link: https://www.bbc.co.uk/news/world-us-canada-66793135?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-12\n",
      "-------------------------------\n",
      "MGM Resorts: Slot machines go down in cyber-attack on firm\n",
      "Customers also report problems with payments and check-in as IT systems go down at MGM Resorts' hotels.\n",
      "Link: https://www.bbc.co.uk/news/technology-66784894?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-12\n",
      "-------------------------------\n",
      "Can new Apple iPhone 15 thunder without lightning?\n",
      "Apple is set to unveil the iPhone 15 later on today without its traditional lightning cable charger.\n",
      "Link: https://www.bbc.co.uk/news/technology-66778527?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-11\n",
      "-------------------------------\n",
      "Google antitrust trial: Tech giant denies abusing power to gain monopoly\n",
      "In a landmark trial brought by the US government, the tech giant denies using illegal practices to gain a monopoly.\n",
      "Link: https://www.bbc.co.uk/news/business-66790608?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-12\n",
      "-------------------------------\n",
      "Spotify denies 30-second trick could make you rich\n",
      "The streaming giant quashes a theory that listening to a song on repeat will rake in the royalties.\n",
      "Link: https://www.bbc.co.uk/news/world-us-canada-66781669?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-11\n",
      "-------------------------------\n",
      "Apple shares slide after China government iPhone ban reports\n",
      "The technology giant's stock market valuation has fallen by almost $200bn in the last two days.\n",
      "Link: https://www.bbc.co.uk/news/business-66748092?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-08\n",
      "-------------------------------\n",
      "Roblox coming to PlayStation 4 and PS5\n",
      "The popular children's gaming platform has more than 60 million players a day, according to the firm.\n",
      "Link: https://www.bbc.co.uk/news/technology-66755095?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-08\n",
      "-------------------------------\n",
      "Tech giants face fines for animal cruelty videos\n",
      "The change to the Online Safety Bill comes as a result of a BBC Eye Investigation into global monkey abuse.\n",
      "Link: https://www.bbc.co.uk/news/uk-politics-66750821?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-08\n",
      "-------------------------------\n",
      "Elon Musk says he withheld Starlink over Crimea to avoid escalation\n",
      "A senior Ukrainian official says this enabled Russian attacks and accuses him of \"committing evil\".\n",
      "Link: https://www.bbc.co.uk/news/world-europe-66752264?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-08\n",
      "-------------------------------\n",
      "Another FTX executive Ryan Salame pleads guilty\n",
      "The pleading comes ahead of the October trial of FTX founder Sam Bankman-Fried.\n",
      "Link: https://www.bbc.co.uk/news/business-66747694?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-08\n",
      "-------------------------------\n",
      "YouTube starts verifying health workers in the UK\n",
      "The plan will help ensure YouTubers are genuinely qualified to dish out medical information.\n",
      "Link: https://www.bbc.co.uk/news/technology-66716501?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-08\n",
      "-------------------------------\n",
      "Period trackers to be reviewed over data concerns\n",
      "Many women are worried about the information they share, the regulator says.\n",
      "Link: https://www.bbc.co.uk/news/technology-66740184?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-07\n",
      "-------------------------------\n",
      "Google: Political adverts must disclose use of AI\n",
      "The announcement follows fears AI-generated images and audio are already infiltrating ads.\n",
      "Link: https://www.bbc.co.uk/news/technology-66739858?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-07\n",
      "-------------------------------\n",
      "Starfield creator on 'choice anxiety', long games and exclusive titles\n",
      "Todd Howard tells the BBC his team wondered if they 'were in over our heads' when creating the game.\n",
      "Link: https://www.bbc.co.uk/news/entertainment-arts-66703504?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-06\n",
      "-------------------------------\n",
      "Government denies U-turn on encrypted messaging row\n",
      "The government states that the tech tools for accessing private messages don't yet exist.\n",
      "Link: https://www.bbc.co.uk/news/technology-66716502?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-06\n",
      "-------------------------------\n",
      "TikTok opens Dublin data centre to ease China spying fears\n",
      "There is concern over the video-sharing app's links with China and who accesses its users' data.\n",
      "Link: https://www.bbc.co.uk/news/technology-66717589?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-05\n",
      "-------------------------------\n",
      "Arm Holdings: Chip giant hopes for market value of more than $50bn\n",
      "The UK-based firm is courting investors as its listing in the US looks to be the biggest of the year.\n",
      "Link: https://www.bbc.co.uk/news/business-66720759?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-06\n",
      "-------------------------------\n",
      "Electoral Commission failed basic security test before hack\n",
      "Whistleblower tells the BBC the election watchdog failed the government-backed Cyber Essentials test.\n",
      "Link: https://www.bbc.co.uk/news/technology-66709556?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-04\n",
      "-------------------------------\n",
      "New iPhone, new charger: Apple bends to EU rules\n",
      "A European Union law will require portable devices to have a common charger by 2024.\n",
      "Link: https://www.bbc.co.uk/news/technology-66708571?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-04\n",
      "-------------------------------\n",
      "EE and Vodafone customers able to call after bug fixed\n",
      "The two providers have offered different accounts of what happened to their networks.\n",
      "Link: https://www.bbc.co.uk/news/technology-66708574?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-05\n",
      "-------------------------------\n",
      "Google's search for an AI future as it turns 25\n",
      "The tech giant celebrates its 25th birthday this month, but faces new threats to its dominance.\n",
      "Link: https://www.bbc.co.uk/news/technology-66659361?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-02\n",
      "-------------------------------\n",
      "Moon base: Bangor scientists design fuel to live in space\n",
      "An energy source which could sustain life on the Moon for long periods has been designed by researchers.\n",
      "Link: https://www.bbc.co.uk/news/uk-wales-66687056?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-04\n",
      "-------------------------------\n",
      "X, formerly Twitter, to collect biometric and employment data\n",
      "The social media firm, formerly Twitter, will gather facial information if premium users give consent.\n",
      "Link: https://www.bbc.co.uk/news/technology-66679922?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-01\n",
      "-------------------------------\n",
      "Tech firms fail to tackle Russian propaganda - EU\n",
      "Russian disinformation has increased on X since Elon Musk's takeover, according to a report.\n",
      "Link: https://www.bbc.co.uk/news/technology-66693156?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-02\n",
      "-------------------------------\n",
      "New tech boosts Dutch drive for sustainable farming\n",
      "In the Netherlands, experiments are underway to ensure future food supply and cut carbon emissions.\n",
      "Link: https://www.bbc.co.uk/news/business-66461769?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-03\n",
      "-------------------------------\n",
      "The firms hoping to cut down on wasted cosmetics\n",
      "By tailoring cosmetics to the individual some firms are hoping to cut waste in the cosmetics industry.\n",
      "Link: https://www.bbc.co.uk/news/business-66585299?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-08-31\n",
      "-------------------------------\n",
      "Pass AI law soon or risk falling behind, MPs warn\n",
      "The commons technology committee urges new legislation for the UK to take lead on AI regulation.\n",
      "Link: https://www.bbc.co.uk/news/technology-66661815?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-08-31\n",
      "-------------------------------\n",
      "Google tests watermark to identify AI images\n",
      "The tech giant's artificial intelligence firm DeepMind unveils measures to counter disinformation.\n",
      "Link: https://www.bbc.co.uk/news/technology-66618852?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-08-29\n",
      "-------------------------------\n",
      "Anonymous Sudan hacks X to put pressure on Elon Musk over Starlink\n",
      "Prolific hackers accused of being a front for Russian cyber-operation shares counter evidence with the BBC.\n",
      "Link: https://www.bbc.co.uk/news/technology-66668053?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-08-31\n",
      "-------------------------------\n",
      "London robotic surgeon celebrates its 10,000th procedure\n",
      "A robotic surgeon called Da Vinci has been performing surgery for nearly 20 years.\n",
      "Link: https://www.bbc.co.uk/news/uk-england-london-66757497?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-09\n",
      "-------------------------------\n",
      "Robots are trained to help revive coral reefs\n",
      "Researchers are experimenting with robots to help speed up the restoration of coral reefs.\n",
      "Link: https://www.bbc.co.uk/news/business-66656369?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-11\n",
      "-------------------------------\n",
      "Elusive Ernie: China's new chatbot has a censorship problem\n",
      "Ernie, Baidu's answer to ChatGPT, is wary of sensitive subjects - and clearly dodges questions.\n",
      "Link: https://www.bbc.co.uk/news/world-asia-66727459?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-09\n",
      "-------------------------------\n",
      "Urban oases combine roof gardens and solar panels\n",
      "Combining solar panels and a roof garden is a tricky and costly engineering task.\n",
      "Link: https://www.bbc.co.uk/news/business-66054688?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-07\n",
      "-------------------------------\n",
      "Long wave radio fans mourn fading frequencies\n",
      "Now disappearing, long wave radio broadcasts once gave a taste of far flung countries and cultures.\n",
      "Link: https://www.bbc.co.uk/news/business-66644709?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-04\n",
      "-------------------------------\n",
      "Why empty lorries are a problem and how to fix it\n",
      "With one third of lorries in the UK driving empty, some hauliers are turning to technology for help.\n",
      "Link: https://www.bbc.co.uk/news/business-66461766?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-08-27\n",
      "-------------------------------\n",
      "Edinburgh Fringe: Can TikTok comedy stars cut it on stage?\n",
      "They have millions of followers, but can they cut it in front of a crowd at the Edinburgh Fringe?\n",
      "Link: https://www.bbc.co.uk/news/entertainment-arts-66569003?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-08-23\n",
      "-------------------------------\n",
      "Virtual reality brings new vision to workplace training\n",
      "Staff are being asked to put on VR goggles when they go on a course or team-building session.\n",
      "Link: https://www.bbc.co.uk/news/business-66393315?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-08-20\n",
      "-------------------------------\n",
      "The eco-friendly glass that's hard to crack\n",
      "Scientists have developed an extremely strong glass which is less energy intensive to make than regular glass.\n",
      "Link: https://www.bbc.co.uk/news/business-66359047?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-08-17\n",
      "-------------------------------\n",
      "Back to the future for India's rice farmers\n",
      "India, the world's biggest rice exporter, is turning to old varieties and new farming techniques.\n",
      "Link: https://www.bbc.co.uk/news/business-66323991?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-08-14\n",
      "-------------------------------\n",
      "Video doorbells: Police champion them but do they cut crime?\n",
      "The smart doorbells have soared in popularity, but they may not help reduce the number of break-ins.\n",
      "Link: https://www.bbc.co.uk/news/business-66360030?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-08-13\n",
      "-------------------------------\n",
      "Will electric flying taxis live up to their promise?\n",
      "Small electric aircraft will be carrying passengers soon in Europe soon, but will they catch on?\n",
      "Link: https://www.bbc.co.uk/news/business-66252187?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-08-07\n",
      "-------------------------------\n",
      "Sea drones: What are they and how much do they cost?\n",
      "Moscow has blamed Ukraine for a series of attacks by sea drones on Russian naval targets.\n",
      "Link: https://www.bbc.co.uk/news/world-europe-66373052?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-09-13\n",
      "-------------------------------\n",
      "New AI systems collide with copyright law\n",
      "Artists are worried that their work is being fed into AI systems and are taking legal action.\n",
      "Link: https://www.bbc.co.uk/news/business-66231268?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-07-31\n",
      "-------------------------------\n",
      "The return of cargo-carrying sail ships\n",
      "As concerns about climate change continue wind-powered shipping is making a comeback.\n",
      "Link: https://www.bbc.co.uk/news/business-66300187?at_medium=RSS&at_campaign=KARANGA\n",
      "Published: 2023-07-30\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import feedparser\n",
    "import email.utils\n",
    "from datetime import datetime\n",
    "\n",
    "#cursor.execute(\"INSERT INTO new_articles (title, summary, link, published) VALUES (%s, %s, %s, %s)\", (article['title'], article['summary'], article['link'], article['published']))\n",
    "\n",
    "RSS_FEEDS = {\n",
    "    'technology': 'http://feeds.bbci.co.uk/news/technology/rss.xml',\n",
    "    'world': 'http://feeds.bbci.co.uk/news/world/rss.xml',\n",
    "    'business': 'http://feeds.bbci.co.uk/news/business/rss.xml',\n",
    "    # ... add more topics and URLs as needed\n",
    "}\n",
    "\n",
    "def get_rss_news(topic):\n",
    "    if topic not in RSS_FEEDS:\n",
    "        print(f\"No RSS feed available for topic: {topic}\")\n",
    "        return []\n",
    "\n",
    "    feed_url = RSS_FEEDS[topic]\n",
    "    feed = feedparser.parse(feed_url)\n",
    "\n",
    "    articles = []\n",
    "    for entry in feed.entries:\n",
    "        article = {\n",
    "            \"title\": entry.title,\n",
    "            \"summary\": entry.summary,\n",
    "            \"link\": entry.link,\n",
    "            \"published\": entry.published\n",
    "        }\n",
    "        articles.append(article)\n",
    "    \n",
    "    return articles\n",
    "\n",
    "topic = 'technology' # or 'world', 'business', etc.\n",
    "articles = get_rss_news(topic)\n",
    "\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "    host='localhost',\n",
    "    port=8889,  \n",
    "    user='root',  \n",
    "    password='root', \n",
    "    database='news_articles_db'\n",
    ")\n",
    "\n",
    "for article in articles[:50]:\n",
    "    # Convert the 'published' date from RSS format to YYYY-MM-DD format for SQL\n",
    "    parsed_date = email.utils.parsedate_to_datetime(article['published'])\n",
    "    article['published'] = parsed_date.date().isoformat()\n",
    "\n",
    "    # Store the article in the database\n",
    "    store_article_in_db(article, connection)\n",
    "\n",
    "    # Print the article (for debugging)\n",
    "    print(article['title'])\n",
    "    print(article['summary'])\n",
    "    print(\"Link:\", article['link'])\n",
    "    print(\"Published:\", article['published'])\n",
    "    print(\"-------------------------------\")\n",
    "\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (4.12.2)\n",
      "Requirement already satisfied: requests in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from requests) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install beautifulsoup4 requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import mysql.connector\n",
    "# Set up the OpenAI API key\n",
    "openai.api_key = '########'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TikTok has opened its first European data centre to alleviate fears over Chinese state surveillance.  The firm says European users' data is now migrating to servers in Dublin, as part of its ongoing response to data privacy concerns around the video-sharing app's links to China. TikTok, which is owned by Chinese firm ByteDance, says it has never given data to Beijing. Critics fear that the Chinese state could request access anytime.  The video-sharing giant is also allowing a European security company access to audit cyber-security and data protection controls.  TikTok has called this \"Project Clover\", nodding to the pivotal role that Ireland is playing. It is running in parallel with \"Project Texas\", which involved promising similar measures to US lawmakers in 2020.  Earlier this year TikTok faced a number of government restrictions on its use on cyber-security and privacy grounds.  A spate of institutions decided to ban the app from officials' devices, including the UK government, the European Parliament, the European Commission, and the EU Council. A key concern of European security officials is the risk that the data that TikTok holds on its users would be accessed by the Chinese state.  Authorities imposing bans have warned that emails, contacts and other communication could be accessed by Beijing as a result of having the app on devices.  As part of its effort to ease these concerns, TikTok will now be storing European user data locally. One data centre in Dublin is now up and running with plans for another in Ireland and one in the Hamar region of Norway. The data of TikTok's more than 150 million European users will be moved through one of these three centres. In an update on the project and alongside the announcement of the first data centre coming online, TikTok vice president for public policy in Europe, Theo Bertram, said a third-party security company would also be used to independently audit TikTok's work at the data centre. Project Clover has tasked NCC Group, a global cyber-security company with offices across Europe, to scrutinise TikTok's data controls and report any incidents.  Stephen Bailey, global director of privacy at NCC Group, said he was proud TikTok had chosen NCC to be the third-party security provider on the project.  \"Our objective scrutiny, monitoring and assurance means platform users in Europe and the UK can have confidence in the enhanced data security standards that TikTok is setting, which go above and beyond European regulatory requirements,\" he said.  TikTok said that NCC Group would identify and respond to any \"suspicious or anomalous access attempts\" and would work on enhancing security.  In the coming months, TikTok and NCC Group will engage with policymakers across Europe to explain how this system will work in practice.  TikTok launches plans to allay China security fears Danish journalists are advised not to use TikTok TikTok says US threatens ban if China stake not sold TikTok banned in UK Parliament over security fears 'Worse than death itself': Survivors describe Libya floods Nasa reveals long-awaited findings of UFO report Russian pilot tried to shoot down British air force jet The US wants to talk to North Korea but doesn't know how New satellite images reveal Libya flood destruction Colombian begged for help but died in UK detention centre 'My family paid $40,000 to bring me back from the dead' Why the Libyan port floods were so catastrophic Shoes to TVs - looting spree ravages war-hit Sudan Why the FBI is still searching for hundreds of Capitol rioters He ended the Bongo dynasty. Now what? Flood-hit Libyan city living through 'doomsday' Florida's first hurricane-proof town The greatest spy novel ever written? Why is everyone crazy about Aperol? © 2023 BBC. The BBC is not responsible for the content of external sites. Read about our approach to external linking.\n",
      "Content for article 'TikTok opens Dublin data centre to ease China spying fears' is too long to summarize.\n",
      "They have millions of followers for their TikTok sketches. But how will four hugely successful creators fare in a live stand-up show at Britain's biggest comedy festival, the Edinburgh Fringe? This is \"one great big Edinburgh experiment\", says Coco Sarel as an introduction and possibly a caveat in case things go wrong. Sarel (900,000 followers) is one of four TikTok comedians who, she says, want to find out if they're any good at stand-up. \"Which is better than four LinkedIn comedians, so you're going to have a decent hour.\" A good gag. A good start. The poster for their joint Fringe show, titled Knock Knock, boasts that the quartet have \"7+ million followers\". It's gone up since that was printed. According to their TikTok profiles, they have 8.6 million followers between them, and 365 million likes. There are a couple of hundred people in this bar. It's a tiny audience compared with their online numbers, but being able to hear the laughter (or not) of a crowd is very different from filming something on your phone at home. As host, Sarel gets stuck straight in with some \"crowd work\". In other words, asking people in the front row what they do for a living and trying to come up with an amusing response. But Sarel struggles to find good banter with the first victims and awkwardly moves on. It's not long before we know the professions of most of the people in the first two rows. Sarel does pluck out some good quips, but when she picks on an audience member who works in marketing, the comedian admits defeat. \"I think crowd work is done!\" She has natural energy and charisma, and has more success with a relatable routine re-enacting a group chat between the typical members of a female friendship group. As MC, Sarel returns in between the other acts. She grows more comfortable and assured, and proves her crowd work can work when she plays matchmaker in the audience. It's all good-natured and this time the awkwardness is intentional. Steven McKell (3.8 million) is - how to put this? - larger-than-life and flamboyant, with a flair for physical comedy that's attracted attention online. His sashay onto the stage could form a TikTok video on its own, but here it only fills five seconds out of his 15-minute slot. After a high-kick and a questionable claim to be a \"one-man entertainment machine - like Beyonce if she was from Fife\", the rest of his set focuses on his family life. As he tells it, they were poor, they fought, they put one of his eight siblings in a tumble dryer and dangled another out of the bedroom window - but they looked out for each other. When the police broke down the front door in a raid one day, his diminutive but fearsome Scottish mother headbutted one of the officers, he says, \"right in the shins\". He has learned the stand-up trick of starting with a grain of truth and embellishing for comic effect. He's a big personality, and manages to hold the crowd by doing more than just goofing around. Ayame Ponder (2.7 million) seems to have built her huge following largely by commentating on videos of things like bottles being rolled down stone steps and watching them smash. Yes, that's a thing on TikTok. She starts her set with tongue-in-cheek brags about being \"a TikTok star\" and \"incredibly famous\", before moving on to everyday topics like dating and the nicknames she's given boyfriends based on their, er, physical attributes. She's as likeable and engaging on stage as she is online, and gets the audience on side without setting them alight. Still, she tells them as she exits: \"I've been amazing, you've been so-so.\" Finally, Henry Rowley (1.2 million) made his name with videos parodying pompous posh people. On stage, his history teacher and his dad both sound uncannily like Richard E Grant, and when he says he wants to branch out it turns out that means parodying posh people at music festivals. He puts his whole body into fully acting out his ridiculous characters, and earns extra laughs by being more blunt and risque than his co-stars. Of the four, he has the most fully-formed act, is the most convincing storyteller, and seems to have the self-possession required for stand-up. So did the experiment work? There were mixed results but overall, yes, these TikTok comedians can cut it on stage. They aren't the only online creators in Edinburgh - Serena Terry aka Mammy Banter (2.2 million) and Abi Clarke (906,000) are among the biggest TikTok names to have brought their own shows. Stand-up is a competitive sport, though. There are 1,535 comedy acts listed at this year's Fringe, and while the social media stars held their own, they'll have to do more than that to stand out on the circuit. At least they have their millions of followers to fall back on if they fail. Knock Knock is at the Pleasance Courtyard Cabaret Bar in Edinburgh until Sunday. Zookeeper pun named funniest Fringe joke TikTok comedy stars try to make it on stage Cost of living will kill stand-up, comic Porter says 'Worse than death itself': Survivors describe Libya floods Nasa reveals long-awaited findings of UFO report Russian pilot tried to shoot down British air force jet The US wants to talk to North Korea but doesn't know how New satellite images reveal Libya flood destruction Colombian begged for help but died in UK detention centre 'My family paid $40,000 to bring me back from the dead' Why the Libyan port floods were so catastrophic Shoes to TVs - looting spree ravages war-hit Sudan Why the FBI is still searching for hundreds of Capitol rioters He ended the Bongo dynasty. Now what? Flood-hit Libyan city living through 'doomsday' Florida's first hurricane-proof town The greatest spy novel ever written? Why is everyone crazy about Aperol? © 2023 BBC. The BBC is not responsible for the content of external sites. Read about our approach to external linking.\n",
      "Content for article 'Edinburgh Fringe: Can TikTok comedy stars cut it on stage?' is too long to summarize.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import openai\n",
    "\n",
    "MAX_TOKENS = 2048\n",
    "CONTENT  = \"\"\n",
    "\n",
    "def fetch_articles_from_db(query_term=None):\n",
    "    # Connect to the database\n",
    "    cursor = connection.cursor(dictionary=True)\n",
    "    \n",
    "    if query_term:\n",
    "        sql = f\"SELECT * FROM news_articles WHERE title LIKE %s OR summary LIKE %s\"\n",
    "        cursor.execute(sql, (f\"%{query_term}%\", f\"%{query_term}%\"))\n",
    "    else:\n",
    "        sql = \"SELECT * FROM news_articles\"\n",
    "        cursor.execute(sql)\n",
    "    \n",
    "    articles = cursor.fetchall()\n",
    "    connection.close()\n",
    "    \n",
    "    return articles\n",
    "\n",
    "\n",
    "def fetch_article_content_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    content = ' '.join([p.get_text() for p in paragraphs])\n",
    "    return content\n",
    "\n",
    "#import openai\n",
    "\n",
    "def ask_chatgpt_for_summary(content):\n",
    "\n",
    "    prompt = f\"Summarize the following article: {content}\"\n",
    "    if len(prompt) > MAX_TOKENS:\n",
    "        return \"Content too long to summarize.\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        model=\"gpt-3.5-turbo-0301\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150  # Adjust based on how long you want the answer to be\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "\n",
    "def store_summary_in_db(article_id, summary):\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        port=8889,\n",
    "        user='root',\n",
    "        password='root',\n",
    "        database='news_articles_db'\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    sql = \"UPDATE news_articles SET summary_gpt = %s WHERE id = %s\"\n",
    "    cursor.execute(sql, (summary, article_id))\n",
    "\n",
    "    connection.commit()\n",
    "    connection.close()\n",
    "\n",
    "\n",
    "def summarize_articles():\n",
    "    articles = fetch_articles_from_db(\"TIKTOK\")\n",
    "    \n",
    "    for article in articles:\n",
    "        url = article['link']\n",
    "        content = fetch_article_content_from_url(url)\n",
    "        CONTENT = content\n",
    "        print(content[0:1000000])  # Printing the first 100 characters for checking\n",
    "\n",
    "        if len(content) > MAX_TOKENS:\n",
    "            print(f\"Content for article '{article['title']}' is too long to summarize.\")\n",
    "            continue\n",
    "\n",
    "        # Call ChatGPT to summarize\n",
    "        summary = ask_chatgpt_for_summary(content)\n",
    "        print(f\"Title: {article['title']}\\nSummary: {summary}\\n\")\n",
    "\n",
    "        # Store the summary in the database\n",
    "        store_summary_in_db(article['id'], summary)\n",
    "\n",
    "summarize_articles()\n",
    "#print(CONTENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 28,\n",
       "  'title': 'TikTok opens Dublin data centre to ease China spying fears',\n",
       "  'summary': \"There is concern over the video-sharing app's links with China and who accesses its users' data.\",\n",
       "  'link': 'https://www.bbc.co.uk/news/technology-66717589?at_medium=RSS&at_campaign=KARANGA',\n",
       "  'published': datetime.date(2023, 9, 5),\n",
       "  'summary_gpt': None},\n",
       " {'id': 48,\n",
       "  'title': 'Edinburgh Fringe: Can TikTok comedy stars cut it on stage?',\n",
       "  'summary': 'They have millions of followers, but can they cut it in front of a crowd at the Edinburgh Fringe?',\n",
       "  'link': 'https://www.bbc.co.uk/news/entertainment-arts-66569003?at_medium=RSS&at_campaign=KARANGA',\n",
       "  'published': datetime.date(2023, 8, 23),\n",
       "  'summary_gpt': None}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_articles_from_db(\"TIKTOK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (1.3.0)\n",
      "Requirement already satisfied: nltk in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (3.2.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.25.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: six in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from nltk) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gensim==3.8.3\n",
      "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from gensim==3.8.3) (1.25.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from gensim==3.8.3) (1.10.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from gensim==3.8.3) (1.15.0)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages (from gensim==3.8.3) (6.4.0)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gensim: filename=gensim-3.8.3-cp39-cp39-macosx_10_9_universal2.whl size=24686057 sha256=b68e7264ae5ddfd142c892e9b5011d3f49d21414521c9b66dab436b795aef4b1\n",
      "  Stored in directory: /Users/mickeyshamah/Library/Caches/pip/wheels/ca/5d/af/618594ec2f28608c1d6ee7d2b7e95a3e9b06551e3b80a491d6\n",
      "Successfully built gensim\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.3.2\n",
      "    Uninstalling gensim-4.3.2:\n",
      "      Successfully uninstalled gensim-4.3.2\n",
      "Successfully installed gensim-3.8.3\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mickeyshamah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mickeyshamah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'has_pattern' from 'gensim.utils' (/Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages/gensim/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Make sure you have the punkt tokenizer downloaded\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenize\u001b[39;00m \u001b[39mimport\u001b[39;00m sent_tokenize\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummarization\u001b[39;00m \u001b[39mimport\u001b[39;00m summarize\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gensim/summarization/__init__.py:3\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m# bring model classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msummarizer\u001b[39;00m \u001b[39mimport\u001b[39;00m summarize, summarize_corpus  \u001b[39m# noqa:F401\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mkeywords\u001b[39;00m \u001b[39mimport\u001b[39;00m keywords  \u001b[39m# noqa:F401\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmz_entropy\u001b[39;00m \u001b[39mimport\u001b[39;00m mz_keywords  \u001b[39m# noqa:F401\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gensim/summarization/summarizer.py:58\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecated\n\u001b[1;32m     57\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummarization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpagerank_weighted\u001b[39;00m \u001b[39mimport\u001b[39;00m pagerank_weighted \u001b[39mas\u001b[39;00m _pagerank\n\u001b[0;32m---> 58\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummarization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtextcleaner\u001b[39;00m \u001b[39mimport\u001b[39;00m clean_text_by_sentences \u001b[39mas\u001b[39;00m _clean_text_by_sentences\n\u001b[1;32m     59\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummarization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommons\u001b[39;00m \u001b[39mimport\u001b[39;00m build_graph \u001b[39mas\u001b[39;00m _build_graph\n\u001b[1;32m     60\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummarization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommons\u001b[39;00m \u001b[39mimport\u001b[39;00m remove_unreachable_nodes \u001b[39mas\u001b[39;00m _remove_unreachable_nodes\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gensim/summarization/textcleaner.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummarization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msyntactic_unit\u001b[39;00m \u001b[39mimport\u001b[39;00m SyntacticUnit\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparsing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m preprocess_documents\n\u001b[0;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m tokenize, has_pattern\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msix\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmoves\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39mrange\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'has_pattern' from 'gensim.utils' (/Users/mickeyshamah/Library/Python/3.9/lib/python/site-packages/gensim/utils.py)"
     ]
    }
   ],
   "source": [
    "#!pip install gensim\n",
    "# !pip install gensim --upgrade\n",
    "!pip install gensim==3.8.3\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "# Make sure you have the punkt tokenizer downloaded\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.summarization import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They have millions of followers for their TikTok sketches.\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF stands for Term Frequency-Inverse Document Frequency. approch!!!\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# If you haven't already, you'll need to download the stopwords and punkt tokenizer models:\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [t for t in tokens if t not in string.punctuation]\n",
    "    tokens = [t for t in tokens if t not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def extract_key_sentences(text, n_sentences=5):\n",
    "    sentences = sent_tokenize(text)\n",
    "    preprocessed_sentences = [preprocess(sent) for sent in sentences]\n",
    "    \n",
    "    vectorizer = TfidfVectorizer().fit(preprocessed_sentences)\n",
    "    tfidf_matrix = vectorizer.transform(preprocessed_sentences)\n",
    "    sentence_scores = tfidf_matrix.sum(axis=1)\n",
    "    \n",
    "    ranked_sentences = [sentences[i] for i in sentence_scores.argsort()[0, -n_sentences:].tolist()[0][::-1]]\n",
    "    \n",
    "    return ' '.join(ranked_sentences)\n",
    "\n",
    "# Test the function\n",
    "\n",
    "text_sample = \"They have millions of followers for their TikTok sketches. But how will four hugely successful creators fare in a live stand-up show at Britains biggest comedy festival, the Edinburgh Fringe? This is one great big Edinburgh experiment, says Coco Sarel as an introduction and possibly a caveat in case things go wrong. Sarel (900,000 followers) is one of four TikTok comedians who, she says, want to find out if they're any good at stand-up. Which is better than four LinkedIn comedians, so youre going to have a decent hour. A good gag. A good start. The poster for their joint Fringe show, titled Knock Knock, boasts that the quartet have 7+ million followers. Its gone up since that was printed. According to their TikTok profiles, they have 8.6 million followers between them, and 365 million likes. There are a couple of hundred people in this bar. Its a tiny audience compared with their online numbers, but being able to hear the laughter (or not) of a crowd is very different from filming something on your phone at home. As host, Sarel gets stuck straight in with some crowd work. In other words, asking people in the front row what they do for a living and trying to come up with an amusing response. But Sarel struggles to find good banter with the first victims and awkwardly moves on. Its not long before we know the professions of most of the people in the first two rows. Sarel does pluck out some good quips, but when she picks on an audience member who works in marketing, the comedian admits defeat. I think crowd work is done! She has natural energy and charisma, and has more success with a relatable routine re-enacting a group chat between the typical members of a female friendship group. As MC, Sarel returns in between the other acts. She grows more comfortable and assured, and proves her crowd work can work when she plays matchmaker in the audience. Its all good-natured and this time the awkwardness is intentional. Steven McKell (3.8 million) is - how to put this? - larger-than-life and flamboyant, with a flair for physical comedy thats attracted attention online. His sashay onto the stage could form a TikTok video on its own, but here it only fills five seconds out of his 15-minute slot. After a high-kick and a questionable claim to be a one-man entertainment machine - like Beyonce if she was from Fife, the rest of his set focuses on his family life. As he tells it, they were poor, they fought, they put one of his eight siblings in a tumble dryer and dangled another out of the bedroom window - but they looked out for each other. When the police broke down the front door in a raid one day, his diminutive but fearsome Scottish mother headbutted one of the officers, he says, right in the shins. He has learned the stand-up trick of starting with a grain of truth and embellishing for comic effect. Hes a big personality, and manages to hold the crowd by doing more than just goofing around. Ayame Ponder (2.7 million) seems to have built her huge following largely by commentating on videos of things like bottles being rolled down stone steps and watching them smash. Yes, thats a thing on TikTok. She starts her set with tongue-in-cheek brags about being a TikTok star and incredibly famous, before moving on to everyday topics like dating and the nicknames shes given boyfriends based on their, er, physical attributes. Shes as likeable and engaging on stage as she is online, and gets the audience on side without setting them alight. Still, she tells them as she exits: Ive been amazing, youve been so-so. Finally, Henry Rowley (1.2 million) made his name with videos parodying pompous posh people. On stage, his history teacher and his dad both sound uncannily like Richard E Grant, and when he says he wants to branch out it turns out that means parodying posh people at music festivals. He puts his whole body into fully acting out his ridiculous characters, and earns extra laughs by being more blunt and risque than his co-stars. Of the four, he has the most fully-formed act, is the most convincing storyteller, and seems to have the self-possession required for stand-up. So did the experiment work? There were mixed results but overall, yes, these TikTok comedians can cut it on stage. They arent the only online creators in Edinburgh - Serena Terry aka Mammy Banter (2.2 million) and Abi Clarke (906,000) are among the biggest TikTok names to have brought their own shows. Stand-up is a competitive sport, though. There are 1,535 comedy acts listed at this year's Fringe, and while the social media stars held their own, they'll have to do more than that to stand out on the circuit. At least they have their millions of followers to fall back on if they fail. Knock Knock is at the Pleasance Courtyard Cabaret Bar in Edinburgh until Sunday. Zookeeper pun named funniest Fringe joke TikTok comedy stars try to make it on stage Cost of living will kill stand-up, comic Porter says 'Worse than death itself': Survivors describe Libya floods Nasa reveals long-awaited findings of UFO report Russian pilot tried to shoot down British air force jet The US wants to talk to North Korea but doesnt know how New satellite images reveal Libya flood destruction Colombian begged for help but died in UK detention centre My family paid $40,000 to bring me back from the dead Why the Libyan port floods were so catastrophic Shoes to TVs - looting spree ravages war-hit Sudan Why the FBI is still searching for hundreds of Capitol rioters He ended the Bongo dynasty. Now what? Flood-hit Libyan city living through doomsday Floridas first hurricane-proof town The greatest spy novel ever written? Why is everyone crazy about Aperol © 2023 BBC. The BBC is not responsible for the content of external sites. Read about our approach to external linking\"\n",
    "article = text_sample\n",
    "key_sentences = extract_key_sentences(article, n_sentences=10)\n",
    "print(key_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mickeyshamah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.summarization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mpunkt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtokenize\u001b[39;00m \u001b[39mimport\u001b[39;00m sent_tokenize\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummarization\u001b[39;00m \u001b[39mimport\u001b[39;00m summarize\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_top_n_sentences_with_gensim\u001b[39m(text, n\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[39m# Tokenize the text into sentences\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     sentences \u001b[39m=\u001b[39m sent_tokenize(text)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim.summarization'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_top_n_sentences_with_gensim(text, n=10):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # If there's less than n sentences, return them all\n",
    "    if len(sentences) <= n:\n",
    "        return sentences\n",
    "    \n",
    "    # Use Gensim's summarize function\n",
    "    summary = summarize(text, ratio=n/len(sentences))\n",
    "    \n",
    "    return sent_tokenize(summary)\n",
    "\n",
    "#text_sample = \"\"\"[your_large_text_here]\"\"\"\n",
    "top_sentences = extract_top_n_sentences_with_gensim(text_sample, 10)\n",
    "for sentence in top_sentences:\n",
    "    print(sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
